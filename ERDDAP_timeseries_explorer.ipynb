{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore ERDDAP timeseries data using Jupyter Widgets\n",
    "Inspired by [Jason Grout's excellent ESIP Tech Dive talk on \"Jupyter Widgets\"](https://youtu.be/CVcrTRQkTxo?t=2596), this notebook uses the `ipyleaflet` and `bqplot` widgets\n",
    "to interactively explore the last two weeks of time series data from an ERDDAP Server. Select a `standard_name` from the list, then click a station to see the time series.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: To access a protected ERDDAP endpoint is protected, you can add a `~/.netrc` file like this:\n",
    "```\n",
    "machine cgoms.coas.oregonstate.edu\n",
    "login <username>\n",
    "password <password>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:34.030546Z",
     "start_time": "2017-12-05T14:06:32.427708Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pendulum` is a drop-in replacement for `datetime`, with more useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:34.208973Z",
     "start_time": "2017-12-05T14:06:34.034555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ipyleaflet` and `bqplot` are both Jupyter widgets, so can interact with Python like any other widget.  Since we want to click on a map in a notebook and get an interactive time series plot, they are perfect tools to use here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:34.287160Z",
     "start_time": "2017-12-05T14:06:34.212983Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipyleaflet as ipyl\n",
    "import bqplot as bq\n",
    "import ipywidgets as ipyw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make working with ERDDAP simpler, we use `erddapy`, a high-level python interface to ERDDAP's RESTful API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:35.666463Z",
     "start_time": "2017-12-05T14:06:34.293175Z"
    }
   },
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code should work with minor modifications on any ERDDAP (v1.64+) endpoint that has `cdm_data_type=timeseries` or `cdm_data_type=point` datasets.  Change the values for other ERDDAP endpoints or regions of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:35.709566Z",
     "start_time": "2017-12-05T14:06:35.675484Z"
    }
   },
   "outputs": [],
   "source": [
    "endpoint = 'http://www.neracoos.org/erddap'\n",
    "\n",
    "initial_standard_name = 'significant_height_of_wind_and_swell_waves'\n",
    "\n",
    "nchar = 3 # number of characters for short dataset name\n",
    "cdm_data_type = 'TimeSeries'\n",
    "center = [42.5, -68]\n",
    "zoom = 6\n",
    "\n",
    "now = pendulum.utcnow()\n",
    "max_time = now\n",
    "min_time = now.subtract(weeks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:35.786751Z",
     "start_time": "2017-12-05T14:06:35.722597Z"
    }
   },
   "outputs": [],
   "source": [
    "endpoint = 'https://cgoms.coas.oregonstate.edu/erddap'\n",
    "\n",
    "initial_standard_name = 'air_temperature'\n",
    "\n",
    "nchar = 3 # number of characters for short dataset name\n",
    "cdm_data_type = 'TimeSeries'\n",
    "center = [44, -124]\n",
    "zoom = 6\n",
    "\n",
    "now = pendulum.utcnow()\n",
    "max_time = now\n",
    "min_time = now.subtract(weeks=2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:36.365135Z",
     "start_time": "2017-12-05T14:06:35.799782Z"
    }
   },
   "outputs": [],
   "source": [
    "e = ERDDAP(server_url=endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the `standard_name` attributes that exist on this ERDDAP endpoint, using [ERDDAP's \"categorize\" service](http://www.neracoos.org/erddap/categorize/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.336461Z",
     "start_time": "2017-12-05T14:06:36.373155Z"
    }
   },
   "outputs": [],
   "source": [
    "url='{}/categorize/standard_name/index.csv'.format(endpoint)\n",
    "\n",
    "r1 = requests.get(url, verify=True)\n",
    "\n",
    "df = pd.read_csv(StringIO(r1.text), skiprows=[1, 2])\n",
    "vars = df['Category'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dropdown menu widget with all the `standard_name` values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.420663Z",
     "start_time": "2017-12-05T14:06:37.347487Z"
    }
   },
   "outputs": [],
   "source": [
    "dpdown = ipyw.Dropdown(options=vars, value=initial_standard_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function convert an ERDDAP timeseries CSV response to a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.446725Z",
     "start_time": "2017-12-05T14:06:37.430687Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_csv(url):\n",
    "    r = requests.get(url, verify=True)\n",
    "    return pd.read_csv(StringIO(r.text), index_col='time', parse_dates=True, skiprows=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function puts lon,lat and datasetID into a GeoJSON feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.493838Z",
     "start_time": "2017-12-05T14:06:37.458754Z"
    }
   },
   "outputs": [],
   "source": [
    "def point(dataset, lon, lat, nchar):\n",
    "    geojsonFeature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\n",
    "            \"datasetID\": dataset,\n",
    "            \"short_dataset_name\": dataset[:nchar]\n",
    "        },\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [lon, lat]\n",
    "        }\n",
    "    };\n",
    "    geojsonFeature['properties']['style'] = {'color': 'Grey'}\n",
    "    return geojsonFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds all the datasets with a given standard_name in the specified time period, and return GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.577037Z",
     "start_time": "2017-12-05T14:06:37.506869Z"
    }
   },
   "outputs": [],
   "source": [
    "def adv_search(e, standard_name, cdm_data_type, min_time, max_time):\n",
    "    try:\n",
    "        search_url = e.get_search_url(response='csv', cdm_data_type=cdm_data_type.lower(), items_per_page=100000,\n",
    "                                  standard_name=standard_name, min_time=min_time, max_time=max_time)\n",
    "        r = requests.get(search_url, verify=True)\n",
    "        df = pd.read_csv(StringIO(r.text))\n",
    "    except:\n",
    "        df = []\n",
    "        if len(var)>14:\n",
    "            v = '{}...'.format(standard_name[:15])\n",
    "        else:\n",
    "            v = standard_name\n",
    "        figure.title = 'No {} found in this time range. Pick another variable.'.format(v)\n",
    "        figure.marks[0].y = 0.0 * figure.marks[0].y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the lon,lat vlaues from allDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.619138Z",
     "start_time": "2017-12-05T14:06:37.590068Z"
    }
   },
   "outputs": [],
   "source": [
    "def alllonlat(e, cdm_data_type, min_time, max_time):\n",
    "    url='{}/tabledap/allDatasets.csv?datasetID%2CminLongitude%2CminLatitude&cdm_data_type=%22{}%22&minTime%3C={}&maxTime%3E={}'.format(e.server_url,cdm_data_type,max_time,min_time)\n",
    "    r = requests.get(url, verify=True)\n",
    "    df = pd.read_csv(StringIO(r.text), skiprows=[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.706347Z",
     "start_time": "2017-12-05T14:06:37.627157Z"
    }
   },
   "outputs": [],
   "source": [
    "def stdname2geojson(e, standard_name, min_time, max_time, nchar):\n",
    "    '''return geojson containing lon, lat and datasetID for all matching stations'''\n",
    "    # find matching datsets using Advanced Search\n",
    "    dfa = adv_search(e, standard_name, cdm_data_type, min_time, max_time)\n",
    "    if isinstance(dfa, pd.DataFrame):\n",
    "        datasets = dfa['Dataset ID'].values\n",
    "        # find lon,lat values from allDatasets \n",
    "        dfll = alllonlat(e, cdm_data_type, min_time, max_time)\n",
    "        # extract lon,lat values of matching datasets from allDatasets dataframe\n",
    "        dfr = dfll[dfll['datasetID'].isin(dfa['Dataset ID'])]\n",
    "        # contruct the GeoJSON using fast itertuples\n",
    "        geojson = {'features':[point(row[1],row[2],row[3],nchar) for row in dfr.itertuples()]}\n",
    "    else:\n",
    "        geojson = {'features':[]}\n",
    "        datasets = []\n",
    "    return geojson, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function updates the time series plot when a station marker is clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.749450Z",
     "start_time": "2017-12-05T14:06:37.714366Z"
    }
   },
   "outputs": [],
   "source": [
    "def click_handler(event=None, id=None, properties=None):\n",
    "    datasetID = properties['datasetID']\n",
    "    kwargs = {'time%3E=': min_time, 'time%3C=': max_time}\n",
    "    df, var = get_data(datasetID, dpdown.value, kwargs)\n",
    "    figure.marks[0].x = df.index\n",
    "    figure.marks[0].y = df[var]\n",
    "    figure.title = '{} - {}'.format(properties['short_dataset_name'], var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function updates the map when a new variable is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.791551Z",
     "start_time": "2017-12-05T14:06:37.762481Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_dpdown(change):\n",
    "    standard_name = change['new']\n",
    "    data, datasets = stdname2geojson(e, standard_name, min_time, max_time, nchar)\n",
    "    feature_layer = ipyl.GeoJSON(data=data)\n",
    "    feature_layer.on_click(click_handler)\n",
    "    map.layers = [map.layers[0], feature_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specifies which function to use when a variable is selected from the dropdown list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.831647Z",
     "start_time": "2017-12-05T14:06:37.802577Z"
    }
   },
   "outputs": [],
   "source": [
    "dpdown.observe(update_dpdown, names=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the specified dataset time series values as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:37.875752Z",
     "start_time": "2017-12-05T14:06:37.845680Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(dataset, standard_name, kwargs):\n",
    "    var = e.get_var_by_attr(dataset_id=dataset, \n",
    "                    standard_name=lambda v: str(v).lower() == standard_name)[0]\n",
    "    download_url = e.get_download_url(dataset_id=dataset, \n",
    "                                  variables=['time',var], response='csv', **kwargs)\n",
    "    df = download_csv(download_url)\n",
    "    return df, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the initial `ipyleaflet` map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:39.387371Z",
     "start_time": "2017-12-05T14:06:37.887781Z"
    }
   },
   "outputs": [],
   "source": [
    "map = ipyl.Map(center=center, zoom=zoom, layout=ipyl.Layout(width='650px', height='350px'))\n",
    "data, datasets = stdname2geojson(e, initial_standard_name, min_time, max_time, nchar)\n",
    "feature_layer = ipyl.GeoJSON(data=data)\n",
    "feature_layer.on_click(click_handler)\n",
    "map.layers = [map.layers[0], feature_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the intitial `bqplot` time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:49.488556Z",
     "start_time": "2017-12-05T14:06:39.395391Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_x = bq.DateScale()\n",
    "sc_y = bq.LinearScale()\n",
    "\n",
    "initial_dataset = datasets[0]\n",
    "kwargs = {'time%3E=': min_time, 'time%3C=': max_time}\n",
    "df, var = get_data(initial_dataset, initial_standard_name, kwargs)\n",
    "time_series = bq.Lines(x=df.index, y=df[var], scales={'x': dt_x, 'y': sc_y})\n",
    "ax_x = bq.Axis(scale=dt_x, label='Time')\n",
    "ax_y = bq.Axis(scale=sc_y, orientation='vertical')\n",
    "figure = bq.Figure(marks=[time_series], axes=[ax_x, ax_y])\n",
    "figure.title = '{} - {}'.format(initial_dataset[:nchar], var)\n",
    "figure.layout.height = '300px'\n",
    "figure.layout.width = '800px'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specifies the widget layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:06:49.555717Z",
     "start_time": "2017-12-05T14:06:49.495573Z"
    }
   },
   "outputs": [],
   "source": [
    "ipyw.VBox([dpdown, map, figure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:widgets]",
   "language": "python",
   "name": "conda-env-widgets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
